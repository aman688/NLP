{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "link ='https://storage.googleapis.com/kagglesdsdata/datasets/362178/763778/restaurant.json?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20201229%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20201229T143627Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=21281e98ee324c427d34dd69ec95e228b6df1b19b888e9edcb441ab7ec987fc7968159e37b768ef7b191169cd681794d554c4a79f0b7d8cd368ba0985649f7089d5c8faacb37b65a17d3dce8edb1312244f8622a4177aa2695e166931c500181d8a3ed36df8b160acf085b2e4f9f014512343b146eb827f8845612b747340330ac8af3ae039a307146b2038cde220856cd621a1766790f4e0f80ac18b78d84d8bad2d9fb8598349d67c38269324d95c1997cca54ee0f98c6bfcd2afc3dd06067b14c767513019d6ae0a542ae1ec4e74b67105c2ae882f85016876dd59269b1fb61ab8b69de9a12f48e1bdb81b15095ec4087af7a6db05d80ae5ac5263e5e25b3/'\n",
    "\n",
    "\n",
    "data = pd.read_json(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>lDJIaF4eYRF4F7g6Zb9euw</td>\n",
       "      <td>lb0QUR5bc4O-Am4hNq9ZGg</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I used to work food service and my manager at ...</td>\n",
       "      <td>2013-01-27 17:54:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1013</td>\n",
       "      <td>vvIzf3pr8lTqE_AOsxmgaA</td>\n",
       "      <td>MAmijW4ooUzujkufYYLMeQ</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>We have been trying Eggplant sandwiches all ov...</td>\n",
       "      <td>2015-04-15 04:50:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1204</td>\n",
       "      <td>UF-JqzMczZ8vvp_4tPK3bQ</td>\n",
       "      <td>slfi6gf_qEYTXy90Sw93sg</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazing Steak and Cheese... Better than any Ph...</td>\n",
       "      <td>2011-03-20 00:57:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1251</td>\n",
       "      <td>geUJGrKhXynxDC2uvERsLw</td>\n",
       "      <td>N_-UepOzAsuDQwOUtfRFGw</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Although I have been going to DeFalco's for ye...</td>\n",
       "      <td>2018-07-17 01:48:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1354</td>\n",
       "      <td>aPctXPeZW3kDq36TRm-CqA</td>\n",
       "      <td>139hD7gkZVzSvSzDPwhNNw</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Highs: Ambience, value, pizza and deserts. Thi...</td>\n",
       "      <td>2018-01-21 10:52:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   review_id                 user_id             business_id  \\\n",
       "109   lDJIaF4eYRF4F7g6Zb9euw  lb0QUR5bc4O-Am4hNq9ZGg  r5PLDU-4mSbde5XekTXSCA   \n",
       "1013  vvIzf3pr8lTqE_AOsxmgaA  MAmijW4ooUzujkufYYLMeQ  r5PLDU-4mSbde5XekTXSCA   \n",
       "1204  UF-JqzMczZ8vvp_4tPK3bQ  slfi6gf_qEYTXy90Sw93sg  r5PLDU-4mSbde5XekTXSCA   \n",
       "1251  geUJGrKhXynxDC2uvERsLw  N_-UepOzAsuDQwOUtfRFGw  r5PLDU-4mSbde5XekTXSCA   \n",
       "1354  aPctXPeZW3kDq36TRm-CqA  139hD7gkZVzSvSzDPwhNNw  r5PLDU-4mSbde5XekTXSCA   \n",
       "\n",
       "      stars  useful  funny  cool  \\\n",
       "109       4       2      0     0   \n",
       "1013      4       0      0     0   \n",
       "1204      5       1      0     0   \n",
       "1251      1       0      0     0   \n",
       "1354      2       0      0     0   \n",
       "\n",
       "                                                   text                date  \n",
       "109   I used to work food service and my manager at ... 2013-01-27 17:54:54  \n",
       "1013  We have been trying Eggplant sandwiches all ov... 2015-04-15 04:50:56  \n",
       "1204  Amazing Steak and Cheese... Better than any Ph... 2011-03-20 00:57:45  \n",
       "1251  Although I have been going to DeFalco's for ye... 2018-07-17 01:48:23  \n",
       "1354  Highs: Ambience, value, pizza and deserts. Thi... 2018-01-21 10:52:58  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = [i for i in data['text'][0:920]] \n",
    "y = data['stars'][0:920]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating the bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector = CountVectorizer(ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_set = count_vector.fit_transform(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing the RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier(n_estimators=100,criterion='entropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC.fit(train_data_set,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.314155942467828"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "data['stars'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = '''\n",
    "Quantum mechanics is a fundamental theory in physics that provides a description of the physical properties of nature at the scale of atoms and subatomic particles.[2]:1.1 It is the foundation of all quantum physics including quantum chemistry, quantum field theory, quantum technology, and quantum information science.\n",
    "Classical physics, the description of physics that existed before the theory of relativity and quantum mechanics, describes many aspects of nature at an ordinary (macroscopic) scale, while quantum mechanics explains the aspects of nature at small (atomic and subatomic) scales, for which classical mechanics is insufficient. \n",
    "Most theories in classical physics can be derived from quantum mechanics as an approximation valid at large (macroscopic) scale.[3]\n",
    "Quantum mechanics differs from classical physics in that energy, momentum, angular momentum, and other quantities of a bound system are restricted to discrete values (quantization), objects have characteristics of both particles and waves (wave-particle duality), and there are limits to how accurately the value of \n",
    "a physical quantity can be predicted prior to its measurement, given a complete set of initial conditions (the uncertainty principle).\n",
    "Quantum mechanics arose gradually, from theories to explain observations which could not be reconciled with classical physics, such as Max Planck's solution in 1900 to the black-body radiation problem, and the correspondence between energy and frequency in Albert Einstein's 1905 paper which explained the photoelectric effect. \n",
    "These early attempts to understand microscopic phenomena, now known as the \"old quantum theory\", led to the full development of quantum mechanics in the mid-1920s by Niels Bohr, Erwin Schrödinger, Werner Heisenberg, Max Born and others. The modern theory is formulated in various specially developed mathematical formalisms. In one of them, a mathematical function, the wave function, provides information about the probability amplitude of energy, momentum, and other physical properties of a particle.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = nltk.word_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mechanics'"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwordswords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')[10:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('french')[2:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('english')) ]\n",
    "    sentence[i]=' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'quantum mechan fundament theori physic provid descript physic properti natur scale atom subatom particl .'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence[0] #converted into base form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nQuantum mechanics is a fundamental theory in physics that provides a description of the physical properties of nature at the scale of atoms and subatomic particles.'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer   # for lematization\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = '''\n",
    "\n",
    "World War I (or the First World War, often abbreviated as WWI or WW1) was a global war originating in Europe that lasted from 28 July 1914 to 11 November 1918. Contemporaneously known as the Great War or \"the war to end all wars\",[7] it led to the mobilisation of more than 70 million military personnel, including 60 million Europeans, making it one of the largest wars in history.[8][9] It is also one of the deadliest conflicts in history,[10] with an estimated 9 million combatant deaths and 13 million civilian deaths as a direct result of the war,[11] while resulting genocides and the related 1918 Spanish flu pandemic caused another 17–100 million deaths worldwide,[12][13] including an estimated 2.64 million Spanish flu deaths in Europe and as many as 675,000 Spanish flu deaths in the United States.[14]\n",
    "\n",
    "On 28 June 1914, Gavrilo Princip, a Bosnian Serb Yugoslav nationalist, assassinated the Austro-Hungarian heir Archduke Franz Ferdinand in Sarajevo, leading to the July Crisis.[15][16] In response, Austria-Hungary issued an ultimatum to Serbia on 23 July. Serbia's reply failed to satisfy the Austrians, and the two moved to a war footing. A network of interlocking alliances enlarged the crisis from a bilateral issue in the Balkans to one involving most of Europe. By July 1914, the great powers of Europe were divided into two coalitions: the Triple Entente, consisting of France, Russia, and Britain; and the Triple Alliance of Germany, Austria-Hungary, and Italy. The Triple Alliance was only defensive in nature, allowing Italy to stay out of the war until April 1915, when it joined the Allied Powers after its relations with Austria-Hungary deteriorated.[17] Russia felt it necessary to back Serbia, and approved partial mobilisation after Austria-Hungary shelled the Serbian capital of Belgrade, which was a few miles from the border, on 28 July.[18] Full Russian mobilisation was announced on the evening of 30 July; the following day, Austria-Hungary and Germany did the same, while Germany demanded Russia demobilise within twelve hours.[19] When Russia failed to comply, Germany declared war on Russia on 1 August in support of Austria-Hungary, the latter following suit on 6 August; France ordered full mobilisation in support of Russia on 2 August.[20]\n",
    "\n",
    "Germany's strategy for a war on two fronts against France and Russia was to rapidly concentrate the bulk of its army in the West to defeat France within 6 weeks, then shift forces to the East before Russia could fully mobilise; this was later known as the Schlieffen Plan.[21] On 2 August, Germany demanded free passage through Belgium, an essential element in achieving a quick victory over France.[22] When this was refused, German forces invaded Belgium on 3 August and declared war on France the same day; the Belgian government invoked the 1839 Treaty of London and, in compliance with its obligations under this treaty, Britain declared war on Germany on 4 August. On 12 August, Britain and France also declared war on Austria-Hungary; on 23 August, Japan sided with Britain, seizing German possessions in China and the Pacific. In November 1914, the Ottoman Empire entered the war on the side of Austria-Hungary and Germany, opening fronts in the Caucasus, Mesopotamia, and the Sinai Peninsula. The war was fought in (and drew upon) each power's colonial empire also, spreading the conflict to Africa and across the globe. The Entente and its allies eventually became known as the Allied Powers, while the grouping of Austria-Hungary, Germany and their allies became known as the Central Powers.\n",
    "\n",
    "The German advance into France was halted at the Battle of the Marne and by the end of 1914, the Western Front settled into a war of attrition, marked by a long series of trench lines that changed little until 1917 (the Eastern Front, by contrast, was marked by much greater exchanges of territory). In 1915, Italy joined the Allied Powers and opened a front in the Alps. Bulgaria joined the Central Powers in 1915 and Greece joined the Allies in 1917, expanding the war in the Balkans. The United States initially remained neutral, though even while neutral it became an important supplier of war materiel to the Allies. Eventually, after the sinking of American merchant ships by German submarines, the declaration by Germany that its navy would resume unrestricted attacks on neutral shipping, and the revelation that Germany was trying to incite Mexico to initiate war against the United States, the U.S. declared war on Germany on 6 April 1917. Trained American forces did not begin arriving at the front in large numbers until mid-1918, but the American Expeditionary Force ultimately reached some two million troops.[23]\n",
    "\n",
    "Though Serbia was defeated in 1915, and Romania joined the Allied Powers in 1916 only to be defeated in 1917, none of the great powers was knocked out of the war until 1918. The 1917 February Revolution in Russia replaced the Monarchy with the Provisional Government, but continuing discontent with the cost of the war led to the October Revolution, the creation of the Soviet Socialist Republic, and the signing of the Treaty of Brest-Litovsk by the new government in March 1918, ending Russia's involvement in the war. Germany now controlled much of eastern Europe and transferred large numbers of combat troops to the Western Front. Using new tactics, the German March 1918 Offensive was initially successful. The Allies fell back and held. The last of the German reserves were exhausted as 10,000 fresh American troops arrived every day. The Allies drove the Germans back in their Hundred Days Offensive, a continual series of attacks to which the Germans had no reply.[24] One by one the Central Powers quit: first Bulgaria (September 29), then the Ottoman Empire (October 31) and the Austro-Hungarian empire (November 3). With its allies defeated, revolution at home, and the military no longer willing to fight, Kaiser Wilhelm abdicated on 9 November and Germany signed an armistice on 11 November 1918, ending the war.\n",
    "\n",
    "World War I was a significant turning point in the political, cultural, economic, and social climate of the world. The war and its immediate aftermath sparked numerous revolutions and uprisings. The Big Four (Britain, France, the United States, and Italy) imposed their terms on the defeated powers in a series of treaties agreed at the 1919 Paris Peace Conference, the most well known being the German peace treaty: the Treaty of Versailles.[25] Ultimately, as a result of the war, the Austro-Hungarian, German, Ottoman, and Russian Empires ceased to exist, and numerous new states were created from their remains. However, despite the conclusive Allied victory (and the creation of the League of Nations during the Peace Conference, intended to prevent future wars), a second world war followed just over twenty years later.\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatization = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [lemmatization.lemmatize(word) for word in words if word not in set(stopwords.words('english')) ]\n",
    "    sentences[i]=' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = '''\n",
    "\n",
    "India attained Independence from British Rule on 15th of August 1947 following Independence movement that largely comprised of non-violence and civil disobedience. Independence accompanied the partition of India on religious lines in two dominions – India and Pakistan. Partition also gave rise to violent riots and mass afflictions. Our Prime Mister Jawaharlal Nehru, the first prime minister of Independent India hoisted the Indian National flag on Red Fort, Delhi on 15th August 1947. Every year 15th August is celebrated as Independence Day and is declared national holiday.\n",
    "\n",
    "Republic Day\n",
    "\n",
    "Republic Day is celebrated on 26th January 1950 when constitution of India came in to effect with democratic government system initiating thenation’s transition towards being an independent republic. 26th of January has been declared as Republic Day as in 1930 on this day declaration of Purna Swaraj (Independence) was claimed.\n",
    "\n",
    "Gandhi Jayanti\n",
    "\n",
    "Gandhi Jayanti is celebrated on second of October, our national leader and freedom fighter Mahatma Gandhi’s birthday.\n",
    "\n",
    "There is nationwide holiday on National festivals. Religious festivals like Diwali, Holi, Raksha Bandhan, Christmas, Ramzan, Guru Nanak Jayanti, Ganesh Chaturthi, Baisakhi, Bihu, Pongal, Basant Panchami and many more are celebrated here with love and unity.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS = PorterStemmer()\n",
    "word_net = WordNetLemmatizer()\n",
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bag of words using stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []  #after cleaning well store data here\n",
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]',' ',sentences[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [PS.stem(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'india attain independ british rule th august follow independ movement larg compris non violenc civil disobedi'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nIndia attained Independence from British Rule on 15th of August 1947 following Independence movement that largely comprised of non-violence and civil disobedience. Independence accompanied the partition of India on religious lines i'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph[0:234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text  import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = CV.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIndia attained Independence from British Rule on'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph[1:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#firstly we will use the re expression to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]',' ',sentences[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lemma.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'india attained independence british rule th august following independence movement largely comprised non violence civil disobedience'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nIndia attained Independence from British Rule on 15th of August 1947 following Independence movement that largely comprised of non-violence and civil disobedience.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_IDF = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = TF_IDF.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('Desktop/SMSSpamCollection',sep='\\t',names=['label','messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                           messages\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['messages'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "PS = PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now cleaning of the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 59.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus=[]\n",
    "for i in range(len(df['messages'])):\n",
    "    review = re.sub('[^a-zA-Z]',' ',df['messages'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lemma.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go jurong point crazy'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['Go until jurong point, crazy..\""
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 59.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus=[]\n",
    "for i in range(len(df['messages'])):\n",
    "    review = re.sub('[^a-zA-Z]',' ',df['messages'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [PS.stem(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go jurong point crazi'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0] #of stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go jurong point crazi'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0] # of lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the bad of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = CountVectorizer(max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = CV.fit_transform(corpus).toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.get_dummies(df['label'])\n",
    "Y = Y.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test= train_test_split(X,Y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_detect_model = MultinomialNB().fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = spam_detect_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[944,   9],\n",
       "       [ 11, 151]], dtype=int64)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_pred,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9820627802690582"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_pred,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
